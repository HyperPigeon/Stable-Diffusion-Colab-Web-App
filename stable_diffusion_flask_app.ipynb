{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wa8shR7k6THe"
      },
      "outputs": [],
      "source": [
        "#Install libraries\n",
        "!pip install --quiet flask\n",
        "!pip install --quiet --upgrade diffusers transformers accelerate mediapy triton scipy ftfy spacy==3.4.4\n",
        "!pip install --quiet -q xformers==0.0.16rc425 \n",
        "!pip install --quiet flask-ngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up Ngrok\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.tgz\n",
        "!tar -xvf /content/ngrok-stable-linux-amd64.tgz\n",
        "\n",
        "!./ngrok authtoken replace_with_user_token"
      ],
      "metadata": {
        "id": "CiOolAYb6nzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "from flask import Flask, render_template, request\n",
        "import requests\n",
        "import base64\n",
        "import numpy as np\n",
        "from flask import Flask\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from diffusers import StableDiffusionPipeline, DiffusionPipeline\n",
        "import torch\n",
        "from torch import autocast\n",
        "import random\n",
        "import io"
      ],
      "metadata": {
        "id": "l6-l4Qmo6zvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set up stable diffusion model\n",
        "\n",
        "model_id = \"stabilityai/stable-diffusion-2-1-base\"\n",
        "\n",
        "scheduler = None\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(model_id)\n",
        "\n",
        "pipe = pipe.to(device)\n",
        "pipe.enable_xformers_memory_efficient_attention()"
      ],
      "metadata": {
        "id": "klbbPBt68v2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Flask setup\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app) "
      ],
      "metadata": {
        "id": "BlBvYRFJ9Ua5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Home page\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "\n",
        "# Handle form submission\n",
        "@app.route('/generate_image', methods=['POST'])\n",
        "def generate_image():\n",
        "    prompt_input = request.form['prompt_text']  \n",
        "    negative_prompt_input = request.form['negative_prompt_text']\n",
        "    image_length_input = request.form['image_length']\n",
        "    image_width_output = request.form['image_width']\n",
        "\n",
        "    generated_image = generate_image_from_text(prompt_input, negative_prompt_input,image_length_input,image_width_output)\n",
        "\n",
        "    image_data = base64.b64encode(generated_image).decode('utf-8')\n",
        "\n",
        "    return render_template('index.html', image_data=image_data, prompt_data = prompt_input, negative_prompt_data = negative_prompt_input)\n",
        "\n",
        "def generate_image_from_text(prompt_input, negative_prompt_input = \"\", length = 512, width = 512):\n",
        "    prompt = prompt_input\n",
        "    negative_prompt = negative_prompt_input\n",
        "    remove_safety = False\n",
        "    image_length = length\n",
        "    image_width = width\n",
        "    num_images = 1\n",
        "    seed = random.randint(0, 2147483647)\n",
        "\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height = image_length,\n",
        "        width = image_length,\n",
        "        num_inference_steps = 25,\n",
        "        guidance_scale = 9,\n",
        "        num_images_per_prompt = num_images,\n",
        "        negative_prompt = negative_prompt,\n",
        "        generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "        ).images\n",
        "\n",
        "    image_bytes = io.BytesIO()\n",
        "    images[0].save(image_bytes, format='PNG')\n",
        "    image_bytes.seek(0)\n",
        "\n",
        "    return image_bytes.getvalue()\n"
      ],
      "metadata": {
        "id": "TlOW7hW-DhD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#start flask web app on ngrok\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "metadata": {
        "id": "AuAtgx4xDy-c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}